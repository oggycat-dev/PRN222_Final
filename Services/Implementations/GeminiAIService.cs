using DAL.Entities;
using DAL.Repositories;
using Services.Interfaces;
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Configuration;
using Mscc.GenerativeAI;
using System.Diagnostics;
using System.Runtime.CompilerServices;

namespace Services.Implementations
{
    public class GeminiAIService : IAIService
    {
        private readonly ILogger<GeminiAIService> _logger;
        private readonly IConfiguration _configuration;
        private readonly IAIUsageRepository _aiUsageRepository;
        private readonly IPromptSessionRepository _promptSessionRepository;
        private readonly GoogleAI _googleAI;
        private readonly string _apiKey;

        public GeminiAIService(
            ILogger<GeminiAIService> logger,
            IConfiguration configuration,
            IAIUsageRepository aiUsageRepository,
            IPromptSessionRepository promptSessionRepository)
        {
            _logger = logger;
            _configuration = configuration;
            _aiUsageRepository = aiUsageRepository;
            _promptSessionRepository = promptSessionRepository;
            
            // Get API key from configuration with better validation
            _apiKey = configuration["GEMINI_API_KEY"] ?? throw new InvalidOperationException("GEMINI_API_KEY is not configured");
            
            if (string.IsNullOrWhiteSpace(_apiKey) || _apiKey == "null")
            {
                throw new InvalidOperationException("GEMINI_API_KEY is not properly configured");
            }
            
            _googleAI = new GoogleAI(_apiKey);
            _logger.LogInformation("GeminiAIService initialized successfully");
        }

        public async Task<AIResponse> SendMessageAsync(string message, int? sessionId = null, int? userId = null)
        {
            try
            {
                var stopwatch = Stopwatch.StartNew();
                
                // Validate input
                if (string.IsNullOrWhiteSpace(message))
                {
                    return new AIResponse
                    {
                        Success = false,
                        Message = "Tin nh·∫Øn kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng.",
                        ErrorDetails = "Empty message provided"
                    };
                }

                // Get the model with updated model name
                var model = _googleAI.GenerativeModel("gemini-1.5-flash");
                
                // Generate response with retry logic
                var response = await GenerateContentWithRetry(model, message, maxRetries: 3);
                stopwatch.Stop();

                var aiResponse = new AIResponse
                {
                    Success = true,
                    Message = "Ph·∫£n h·ªìi AI th√†nh c√¥ng.",
                    Response = response.Text ?? "Kh√¥ng c√≥ ph·∫£n h·ªìi t·ª´ AI.",
                    TokensUsed = EstimateTokens(message + (response.Text ?? "")),
                    Metadata = new AIResponseMetadata
                    {
                        Model = "gemini-1.5-flash",
                        ProcessingTimeMs = stopwatch.ElapsedMilliseconds,
                        TotalTokens = EstimateTokens(message + (response.Text ?? "")),
                        PromptTokens = EstimateTokens(message),
                        CompletionTokens = EstimateTokens(response.Text ?? "")
                    }
                };

                // Log usage if userId is provided
                if (userId.HasValue)
                {
                    await LogUsageAsync(userId.Value, "gemini-1.5-flash", message, response.Text ?? "", 
                                      aiResponse.TokensUsed, stopwatch.ElapsedMilliseconds, sessionId, true);
                }

                _logger.LogInformation($"AI response generated successfully for user {userId}. Tokens: {aiResponse.TokensUsed}, Time: {stopwatch.ElapsedMilliseconds}ms");
                
                return aiResponse;
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, $"Error generating AI response for user {userId}");
                
                // Log failed usage if userId is provided
                if (userId.HasValue)
                {
                    await LogUsageAsync(userId.Value, "gemini-1.5-flash", message, "", 0, 0, sessionId, false, ex.Message);
                }

                // Provide user-friendly error messages
                string userMessage;
                if (ex.Message.Contains("Service Unavailable") || ex.Message.Contains("503"))
                {
                    userMessage = "üöß Gemini AI hi·ªán t·∫°i ƒëang b·∫£o tr√¨. Vui l√≤ng th·ª≠ l·∫°i sau v√†i ph√∫t.";
                }
                else if (ex.Message.Contains("Too Many Requests") || ex.Message.Contains("429"))
                {
                    userMessage = "‚è∞ ƒê√£ v∆∞·ª£t qu√° gi·ªõi h·∫°n s·ªë l·∫ßn g·ªçi API. Vui l√≤ng th·ª≠ l·∫°i sau v√†i ph√∫t.";
                }
                else if (ex.Message.Contains("unauthorized") || ex.Message.Contains("401"))
                {
                    userMessage = "üîë L·ªói x√°c th·ª±c API. Vui l√≤ng li√™n h·ªá qu·∫£n tr·ªã vi√™n.";
                }
                else if (ex.Message.Contains("quota") || ex.Message.Contains("limit"))
                {
                    userMessage = "üìä ƒê√£ h·∫øt quota API. Vui l√≤ng th·ª≠ l·∫°i v√†o ng√†y mai.";
                }
                else if (ex.Message.StartsWith("Gemini AI"))
                {
                    userMessage = ex.Message; // Use our custom retry messages
                }
                else
                {
                    userMessage = "‚ùå ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh khi k·∫øt n·ªëi v·ªõi AI. Vui l√≤ng th·ª≠ l·∫°i.";
                }

                return new AIResponse
                {
                    Success = false,
                    Message = userMessage,
                    ErrorDetails = ex.Message
                };
            }
        }

        public async Task<AIResponse> SendMessageWithContextAsync(string message, List<ChatMessage> chatHistory, int? userId = null)
        {
            try
            {
                var stopwatch = Stopwatch.StartNew();
                
                // Build conversation context
                var contextBuilder = new System.Text.StringBuilder();
                
                // Add chat history
                foreach (var historyMessage in chatHistory.TakeLast(10)) // Limit to last 10 messages
                {
                    var roleLabel = historyMessage.Role == "user" ? "Ng∆∞·ªùi d√πng" : "AI";
                    contextBuilder.AppendLine($"{roleLabel}: {historyMessage.Content}");
                }
                
                // Add current message
                contextBuilder.AppendLine($"Ng∆∞·ªùi d√πng: {message}");
                contextBuilder.AppendLine("AI:");

                var fullPrompt = contextBuilder.ToString();
                
                // Get the model with updated model name
                var model = _googleAI.GenerativeModel("gemini-1.5-flash");
                
                // Generate response
                var response = await model.GenerateContent(fullPrompt);
                stopwatch.Stop();

                var aiResponse = new AIResponse
                {
                    Success = true,
                    Message = "Ph·∫£n h·ªìi AI v·ªõi ng·ªØ c·∫£nh th√†nh c√¥ng.",
                    Response = response.Text ?? "Kh√¥ng c√≥ ph·∫£n h·ªìi t·ª´ AI.",
                    TokensUsed = EstimateTokens(fullPrompt + (response.Text ?? "")),
                    Metadata = new AIResponseMetadata
                    {
                        Model = "gemini-1.5-flash",
                        ProcessingTimeMs = stopwatch.ElapsedMilliseconds,
                        TotalTokens = EstimateTokens(fullPrompt + (response.Text ?? "")),
                        PromptTokens = EstimateTokens(fullPrompt),
                        CompletionTokens = EstimateTokens(response.Text ?? "")
                    }
                };

                // Log usage if userId is provided
                if (userId.HasValue)
                {
                    await LogUsageAsync(userId.Value, "gemini-1.5-flash", message, response.Text ?? "", 
                                      aiResponse.TokensUsed, stopwatch.ElapsedMilliseconds, null, true);
                }

                _logger.LogInformation($"AI contextual response generated successfully for user {userId}. Tokens: {aiResponse.TokensUsed}");
                
                return aiResponse;
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, $"Error generating AI contextual response for user {userId}");
                
                return new AIResponse
                {
                    Success = false,
                    Message = "ƒê√£ x·∫£y ra l·ªói khi t·∫°o ph·∫£n h·ªìi AI v·ªõi ng·ªØ c·∫£nh.",
                    ErrorDetails = ex.Message
                };
            }
        }

        public async Task<AIResponse> GenerateResponseAsync(string prompt, AIOptions? options = null)
        {
            try
            {
                var stopwatch = Stopwatch.StartNew();
                
                // Get the model with updated model name
                var model = _googleAI.GenerativeModel("gemini-1.5-flash");
                
                // Configure generation config if options provided
                if (options != null)
                {
                    // Note: Mscc.GenerativeAI may have different parameter names
                    // This is a basic implementation, adjust based on actual library API
                }
                
                // Generate response
                var response = await model.GenerateContent(prompt);
                stopwatch.Stop();

                return new AIResponse
                {
                    Success = true,
                    Message = "T·∫°o ph·∫£n h·ªìi th√†nh c√¥ng.",
                    Response = response.Text ?? "Kh√¥ng c√≥ ph·∫£n h·ªìi t·ª´ AI.",
                    TokensUsed = EstimateTokens(prompt + (response.Text ?? "")),
                    Metadata = new AIResponseMetadata
                    {
                        Model = "gemini-1.5-flash",
                        ProcessingTimeMs = stopwatch.ElapsedMilliseconds,
                        TotalTokens = EstimateTokens(prompt + (response.Text ?? "")),
                        PromptTokens = EstimateTokens(prompt),
                        CompletionTokens = EstimateTokens(response.Text ?? "")
                    }
                };
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Error generating AI response with options");
                
                return new AIResponse
                {
                    Success = false,
                    Message = "ƒê√£ x·∫£y ra l·ªói khi t·∫°o ph·∫£n h·ªìi AI.",
                    ErrorDetails = ex.Message
                };
            }
        }

        public async Task<AIResponse> GenerateTextAsync(string prompt, int maxTokens = 1000)
        {
            var options = new AIOptions
            {
                MaxTokens = maxTokens,
                Model = "gemini-1.5-flash"
            };
            
            return await GenerateResponseAsync(prompt, options);
        }

        public async Task<AIResponse> SummarizeTextAsync(string text, int maxLength = 500)
        {
            var prompt = $"H√£y t√≥m t·∫Øt ƒëo·∫°n vƒÉn b·∫£n sau trong kho·∫£ng {maxLength} t·ª´ b·∫±ng ti·∫øng Vi·ªát:\n\n{text}";
            
            var options = new AIOptions
            {
                MaxTokens = maxLength + 100, // Add some buffer
                Model = "gemini-1.5-flash"
            };
            
            return await GenerateResponseAsync(prompt, options);
        }

        public async Task<AIResponse> TranslateTextAsync(string text, string targetLanguage = "vi")
        {
            var languageName = targetLanguage.ToLower() switch
            {
                "vi" => "ti·∫øng Vi·ªát",
                "en" => "ti·∫øng Anh",
                "fr" => "ti·∫øng Ph√°p",
                "de" => "ti·∫øng ƒê·ª©c",
                "es" => "ti·∫øng T√¢y Ban Nha",
                "ja" => "ti·∫øng Nh·∫≠t",
                "ko" => "ti·∫øng H√†n",
                "zh" => "ti·∫øng Trung",
                _ => targetLanguage
            };
            
            var prompt = $"H√£y d·ªãch ƒëo·∫°n vƒÉn b·∫£n sau sang {languageName}:\n\n{text}";
            
            return await GenerateResponseAsync(prompt);
        }

        public async Task<bool> ValidateAPIConnectionAsync()
        {
            try
            {
                var model = _googleAI.GenerativeModel("gemini-1.5-flash");
                var response = await model.GenerateContent("Hello, test connection.");
                
                return !string.IsNullOrEmpty(response.Text);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to validate Gemini API connection");
                return false;
            }
        }

        public async Task<AIUsageStats> GetUsageStatsAsync(int userId)
        {
            try
            {
                var totalRequests = await _aiUsageRepository.GetUserTotalRequestsAsync(userId);
                var totalTokens = await _aiUsageRepository.GetUserTotalTokensAsync(userId);
                var requestsToday = await _aiUsageRepository.GetUserRequestsTodayAsync(userId);
                var tokensToday = await _aiUsageRepository.GetUserTokensTodayAsync(userId);
                var lastUsed = await _aiUsageRepository.GetUserLastUsageAsync(userId);

                return new AIUsageStats
                {
                    UserId = userId,
                    TotalRequests = totalRequests,
                    TotalTokensUsed = totalTokens,
                    RequestsToday = requestsToday,
                    TokensToday = tokensToday,
                    LastUsed = lastUsed ?? DateTime.MinValue
                };
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, $"Error getting usage stats for user {userId}");
                return new AIUsageStats { UserId = userId };
            }
        }

        private async Task LogUsageAsync(int userId, string model, string prompt, string response, 
                                       int tokensUsed, double processingTimeMs, int? sessionId, 
                                       bool isSuccess, string? errorMessage = null)
        {
            try
            {
                var aiUsage = new AIUsage
                {
                    UserId = userId,
                    Model = model,
                    Prompt = prompt.Length > 2000 ? prompt.Substring(0, 2000) : prompt,
                    Response = response,
                    TokensUsed = tokensUsed,
                    PromptTokens = EstimateTokens(prompt),
                    CompletionTokens = EstimateTokens(response),
                    ProcessingTimeMs = processingTimeMs,
                    PromptSessionId = sessionId,
                    IsSuccess = isSuccess,
                    ErrorMessage = errorMessage
                };

                await _aiUsageRepository.CreateAsync(aiUsage);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, $"Failed to log AI usage for user {userId}");
            }
        }

        private async Task<Mscc.GenerativeAI.GenerateContentResponse> GenerateContentWithRetry(
            Mscc.GenerativeAI.GenerativeModel model, 
            string message, 
            int maxRetries = 3)
        {
            var attempt = 0;
            while (attempt < maxRetries)
            {
                try
                {
                    _logger.LogInformation($"üîÑ Gemini API attempt {attempt + 1}/{maxRetries}");
                    var response = await model.GenerateContent(message);
                    _logger.LogInformation($"‚úÖ Gemini API succeeded on attempt {attempt + 1}");
                    return response;
                }
                catch (HttpRequestException ex) when (ex.Message.Contains("503") || ex.Message.Contains("Service Unavailable"))
                {
                    attempt++;
                    if (attempt >= maxRetries)
                    {
                        _logger.LogError($"‚ùå Gemini API failed after {maxRetries} attempts: {ex.Message}");
                        throw new Exception($"Gemini AI hi·ªán t·∫°i kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng th·ª≠ l·∫°i sau v√†i ph√∫t. (ƒê√£ th·ª≠ {maxRetries} l·∫ßn)");
                    }

                    var delay = TimeSpan.FromSeconds(Math.Pow(2, attempt)); // Exponential backoff: 2s, 4s, 8s
                    _logger.LogWarning($"‚ö†Ô∏è Gemini API attempt {attempt} failed (503 Service Unavailable). Retrying in {delay.TotalSeconds}s...");
                    await Task.Delay(delay);
                }
                catch (HttpRequestException ex) when (ex.Message.Contains("429") || ex.Message.Contains("Too Many Requests"))
                {
                    attempt++;
                    if (attempt >= maxRetries)
                    {
                        _logger.LogError($"‚ùå Gemini API rate limited after {maxRetries} attempts");
                        throw new Exception("ƒê√£ v∆∞·ª£t qu√° gi·ªõi h·∫°n s·ªë l·∫ßn g·ªçi API. Vui l√≤ng th·ª≠ l·∫°i sau v√†i ph√∫t.");
                    }

                    var delay = TimeSpan.FromSeconds(Math.Pow(2, attempt + 2)); // Longer delay for rate limits: 8s, 16s, 32s
                    _logger.LogWarning($"‚ö†Ô∏è Gemini API rate limited on attempt {attempt}. Retrying in {delay.TotalSeconds}s...");
                    await Task.Delay(delay);
                }
                catch (Exception ex)
                {
                    _logger.LogError($"‚ùå Gemini API failed with non-retryable error: {ex.Message}");
                    throw; // Re-throw non-retryable exceptions immediately
                }
            }

            throw new Exception($"Gemini AI kh√¥ng th·ªÉ x·ª≠ l√Ω y√™u c·∫ßu sau {maxRetries} l·∫ßn th·ª≠.");
        }

        private int EstimateTokens(string text)
        {
            if (string.IsNullOrEmpty(text))
                return 0;
            
            // Rough estimation: 1 token ‚âà 4 characters for most languages
            // This is a simplified estimation, real token counting would require the actual tokenizer
            return (int)Math.Ceiling(text.Length / 4.0);
        }
    }
} 